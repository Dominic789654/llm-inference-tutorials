# LLM æ¨ç†ç³»ç»Ÿæ·±åº¦æ•™å­¦

> ä»é›¶æŒæ¡ vLLMã€SGLang ç­‰ç°ä»£ LLM æ¨ç†æ¡†æ¶çš„æ ¸å¿ƒåŸç†ä¸å®ç°

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)

## ğŸ“š ç®€ä»‹

æœ¬ä»“åº“åŒ…å«ä¸€ç³»åˆ—æ·±å…¥æµ…å‡ºçš„ LLM æ¨ç†ç³»ç»Ÿæ•™å­¦æ–‡æ¡£ï¼Œæ—¨åœ¨å¸®åŠ©å­¦ä¹ è€…ï¼š

- âœ… ç†è§£ç°ä»£ LLM æ¨ç†æ¡†æ¶çš„æ ¸å¿ƒåŸç†
- âœ… æŒæ¡ PagedAttentionã€Radix Cache ç­‰å…³é”®æŠ€æœ¯
- âœ… å­¦ä¹  Chunked Prefillã€Overlap Scheduling ç­‰é«˜çº§ä¼˜åŒ–
- âœ… å¯¹æ¯”ä¸åŒæ¡†æ¶çš„è®¾è®¡æƒè¡¡
- âœ… è·å¾—å®é™…å¼€å‘å’Œä¼˜åŒ–èƒ½åŠ›

## ğŸ¯ ä¸ºä»€ä¹ˆå­¦ä¹  LLM æ¨ç†ç³»ç»Ÿï¼Ÿ

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ç³»ç»Ÿæ˜¯å½“å‰ AI é¢†åŸŸçš„çƒ­ç‚¹ï¼ŒæŒæ¡ç›¸å…³æŠ€æœ¯å¯ä»¥ï¼š

1. **æå‡æ¨ç†æ€§èƒ½**ï¼šä» 50 tok/s æå‡åˆ° 2000+ tok/sï¼ˆ40x åŠ é€Ÿï¼‰
2. **é™ä½ç¡¬ä»¶æˆæœ¬**ï¼šé€šè¿‡ä¼˜åŒ–æ˜¾è‘—å‡å°‘ GPU éœ€æ±‚
3. **æ„å»ºç”Ÿäº§æœåŠ¡**ï¼šæ­å»ºé«˜å¹¶å‘ã€ä½å»¶è¿Ÿçš„åœ¨çº¿æœåŠ¡
4. **æ·±å…¥ AI ç³»ç»Ÿ**ï¼šç†è§£åˆ†å¸ƒå¼ç³»ç»Ÿã€CUDA ä¼˜åŒ–ã€è°ƒåº¦ç®—æ³•ç­‰

## ğŸ“– æ–‡æ¡£åˆ—è¡¨

### æ ¸å¿ƒæ•™ç¨‹

| æ–‡æ¡£ | å†…å®¹ | éš¾åº¦ | æ—¶é—´ |
|------|------|------|------|
| **[nano-vLLM æ•™å­¦æŒ‡å—](./VLLM_TUTORIAL.md)** | ä»é›¶ç†è§£ vLLMï¼šPagedAttentionã€Schedulerã€KV Cache ç®¡ç† | â­â­ | 1-2 å‘¨ |
| **[mini-sglang æ•™å­¦æŒ‡å—](./MINI_SGLANG_TUTORIAL.md)** | æ·±å…¥ Radix Cacheã€Chunked Prefillã€Overlap Scheduling | â­â­â­â­ | 3-4 å‘¨ |
| **[æ¡†æ¶å¯¹æ¯”åˆ†æ](./NANO_VLLM_COMPARISON.md)** | nano-vLLM vs mini-sglang å…¨é¢å¯¹æ¯” | â­â­â­ | 1 å‘¨ |

### æ¨èå­¦ä¹ è·¯å¾„

```
åˆå­¦è€…è·¯å¾„ï¼ˆ1-2 æœˆï¼‰ï¼š
â”œâ”€ ç¬¬ 1-2 å‘¨ï¼šVLLM_TUTORIAL.md
â”‚   â”œâ”€ PagedAttention åŸç†
â”‚   â”œâ”€ Scheduler è°ƒåº¦ç­–ç•¥
â”‚   â”œâ”€ KV Cache ç®¡ç†æœºåˆ¶
â”‚   â””â”€ Continuous Batching
â”‚
â”œâ”€ ç¬¬ 3 å‘¨ï¼šNANO_VLLM_COMPARISON.md
â”‚   â”œâ”€ ç†è§£ä¸åŒæ¶æ„é€‰æ‹©
â”‚   â”œâ”€ å¯¹æ¯”æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯
â”‚   â””â”€ é€‰æ‹©åˆé€‚æ¡†æ¶
â”‚
â””â”€ ç¬¬ 4-8 å‘¨ï¼šMINI_SGLANG_TUTORIAL.md
    â”œâ”€ Radix Cache å®ç°
    â”œâ”€ Chunked Prefill æœºåˆ¶
    â”œâ”€ Overlap Scheduling
    â”œâ”€ åˆ†å¸ƒå¼æ¶æ„
    â””â”€ è‡ªå®šä¹‰ CUDA Kernels

è¿›é˜¶è·¯å¾„ï¼ˆ3-6 æœˆï¼‰ï¼š
â”œâ”€ æ·±å…¥æºç é˜…è¯»
â”œâ”€ å®ç°è‡ªå®šä¹‰ä¼˜åŒ–
â”œâ”€ æ€§èƒ½åˆ†æå’Œè°ƒä¼˜
â””â”€ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
```

## ğŸ”‘ æ ¸å¿ƒæŠ€æœ¯è¦ç‚¹

### 1. PagedAttention
- **é—®é¢˜**ï¼šä¼ ç»Ÿ KV Cache æµªè´¹ä¸¥é‡
- **è§£å†³**ï¼šå€Ÿé‰´æ“ä½œç³»ç»Ÿè™šæ‹Ÿå†…å­˜ï¼Œåˆ†é¡µç®¡ç†
- **æ•ˆæœ**ï¼šæ˜¾å­˜åˆ©ç”¨ç‡ä» 30% æå‡åˆ° 90%+

### 2. Radix Cache
- **é—®é¢˜**ï¼šå“ˆå¸Œç¼“å­˜åªèƒ½åŒ¹é…å®Œæ•´å—
- **è§£å†³**ï¼šå‰ç¼€æ ‘è‡ªåŠ¨åŒ¹é…ï¼Œæ”¯æŒéƒ¨åˆ†å‰ç¼€
- **æ•ˆæœ**ï¼šç¼“å­˜å‘½ä¸­ç‡æå‡ 1.5-2x

### 3. Chunked Prefill
- **é—®é¢˜**ï¼šé•¿ prompt éœ€è¦ OOM é£é™©
- **è§£å†³**ï¼šåˆ†ç‰‡å¤„ç†é•¿åºåˆ—
- **æ•ˆæœ**ï¼šå³°å€¼æ˜¾å­˜é™ä½ 25x

### 4. Overlap Scheduling
- **é—®é¢˜**ï¼šCPU è°ƒåº¦å¼€é”€å¤§
- **è§£å†³**ï¼šCPU/GPU å¹¶è¡Œæ‰§è¡Œ
- **æ•ˆæœ**ï¼šååé‡æå‡ 1.5x

### 5. Continuous Batching
- **é—®é¢˜**ï¼šé™æ€æ‰¹å¤„ç†ç­‰å¾…æ…¢è¯·æ±‚
- **è§£å†³**ï¼šåŠ¨æ€æ‰¹å¤„ç†ï¼Œè¯·æ±‚å®Œæˆå³ç§»é™¤
- **æ•ˆæœ**ï¼šååé‡æå‡ 4x

## ğŸ’¡ ç‰¹è‰²äº®ç‚¹

### ğŸ“Š ä¸°å¯Œçš„ç¤ºä¾‹ä»£ç 

æ¯ä¸ªæ¦‚å¿µéƒ½é…æœ‰è¯¦ç»†çš„ä»£ç ç¤ºä¾‹ï¼š

```python
# PagedAttention å—åˆ†é…ç¤ºä¾‹
seq = Sequence([1, 2, 3, ..., 1000])
manager.allocate(seq)
# seq.block_table = [0, 1, 2, 3]
```

### ğŸ¨ å¯è§†åŒ–å›¾ç¤º

ä½¿ç”¨ ASCII å›¾ç¤ºå±•ç¤ºå¤æ‚æ¦‚å¿µï¼š

```
ä¼ ç»Ÿæ–¹å¼ï¼šè¿ç»­åˆ†é…
è¯·æ±‚A: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 1000 tokens
è¯·æ±‚B: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]              100 tokens
       â†‘ æµªè´¹ï¼šéœ€è¦é¢„åˆ†é…

PagedAttentionï¼šåˆ†é¡µç®¡ç†
è¯·æ±‚A: [â–ˆâ–ˆ][â–ˆâ–ˆ][â–ˆâ–ˆ][â–ˆâ–ˆ] 4ä¸ªå—
è¯·æ±‚B: [â–ˆâ–ˆ]             1ä¸ªå—
       â†‘ æŒ‰éœ€åˆ†é…
```

### ğŸ”¢ å®æˆ˜ç»ƒä¹ 

æ¯ç« åŒ…å«å®æˆ˜ç»ƒä¹ ï¼Œå·©å›ºç†è§£ï¼š

- ç»ƒä¹  1ï¼šæ‰‹åŠ¨ç”»å‡º Radix æ ‘ç»“æ„
- ç»ƒä¹  2ï¼šæ¨¡æ‹Ÿ Chunked Prefill è°ƒåº¦
- ç»ƒä¹  3ï¼šè®¡ç®— Overhead å’Œæ€§èƒ½æå‡
- ç»ƒä¹  4ï¼šå¯¹æ¯”ç¼“å­˜å‘½ä¸­ç‡
- ç»ƒä¹  5ï¼šè®¡ç®—åˆ†å¸ƒå¼é€šä¿¡é‡

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

### æ•™å­¦é¡¹ç›®
- **nano-vLLM**: [https://github.com/tzular/mini-vllm](https://github.com/tzular/mini-vllm)
  - 2000 è¡Œ Python
  - é€‚åˆå­¦ä¹ æ ¸å¿ƒæ¦‚å¿µ

- **mini-sglang**: [https://github.com/sgl-project/mini-sglang](https://github.com/sgl-project/mini-sglang)
  - 5000 è¡Œ Python + CUDA
  - ç”Ÿäº§çº§å®ç°

### å…³é”®ä¾èµ–
- PyTorch
- FlashAttention / FlashInfer
- Triton / TVM
- ZeroMQ
- FastAPI

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | HuggingFace | vLLM | SGLang |
|------|-------------|------|--------|
| **ååé‡** | 50 tok/s | 2000 tok/s | 3000 tok/s |
| **æ˜¾å­˜åˆ©ç”¨ç‡** | 30% | 90% | 95% |
| **å¹¶å‘èƒ½åŠ›** | 8 è¯·æ±‚ | 256 è¯·æ±‚ | 512 è¯·æ±‚ |
| **å‰ç¼€ç¼“å­˜** | ä¸æ”¯æŒ | 10-100x | 10-100x |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†ä»“åº“

```bash
git clone https://github.com/YOUR_USERNAME/llm-inference-tutorials.git
cd llm-inference-tutorials
```

### 2. é€‰æ‹©å­¦ä¹ è·¯å¾„

```bash
# åˆå­¦è€…ï¼šä» nano-vLLM å¼€å§‹
cat VLLM_TUTORIAL.md

# æœ‰ç»éªŒï¼šç›´æ¥çœ‹ mini-sglang
cat MINI_SGLANG_TUTORIAL.md

# æƒ³å¯¹æ¯”ï¼šçœ‹å¯¹æ¯”æ–‡æ¡£
cat NANO_VLLM_COMPARISON.md
```

### 3. åŠ¨æ‰‹å®è·µ

```bash
# å…‹éš†æ•™å­¦é¡¹ç›®
git clone https://github.com/tzular/mini-vllm.git
cd mini-vllm

# è¿è¡Œç¤ºä¾‹
python example.py

# å¼€å§‹ä¿®æ”¹å’Œå®éªŒ
vim nanovllm/engine/scheduler.py
```

## ğŸ“š å‚è€ƒèµ„æº

### è®ºæ–‡
- **PagedAttention**: [vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention](https://arxiv.org/abs/2309.06180)
- **RadixAttention**: [SGLang: Efficient Execution of Large Language Models with Structured Generation](https://arxiv.org/abs/2312.07157)
- **Chunked Prefill**: [Sarathi-Serve: Efficient LLM Serving over PCIe and NVLink](https://arxiv.org/abs/2403.02310)

### é¡¹ç›®
- [vLLM](https://github.com/vllm-project/vllm) - ç”Ÿäº§çº§ LLM æ¨ç†æœåŠ¡
- [SGLang](https://github.com/sgl-project/sglang) - ç»“æ„åŒ–ç”Ÿæˆæ¨ç†å¼•æ“
- [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) - NVIDIA ä¼˜åŒ–å¼•æ“

### å·¥å…·
- [FlashAttention](https://github.com/Dao-AILab/flash-attention) - å¿«é€Ÿæ³¨æ„åŠ›å®ç°
- [FlashInfer](https://github.com/flashinfer-ai/flashinfer) - é«˜æ•ˆ LLM æ¨ç†åº“
- [Triton](https://github.com/openai/triton) - Python GPU ç¼–ç¨‹

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼

### å¦‚ä½•è´¡çŒ®

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. å¼€å¯ Pull Request

### è´¡çŒ®æ–¹å‘

- ğŸ“ ä¿®æ­£é”™åˆ«å­—å’Œè¡¨è¾¾
- â• æ·»åŠ æ–°çš„æ•™å­¦ç« èŠ‚
- ğŸ¨ æ”¹è¿›ç¤ºä¾‹ä»£ç 
- ğŸ“Š è¡¥å……æ€§èƒ½æµ‹è¯•
- ğŸŒ ç¿»è¯‘æˆå…¶ä»–è¯­è¨€

## ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸŒŸ Star History

å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª Star â­ï¸

## ğŸ“® è”ç³»æ–¹å¼

- æäº¤ Issueï¼š[GitHub Issues](https://github.com/YOUR_USERNAME/llm-inference-tutorials/issues)
- é‚®ä»¶ï¼šyour.email@example.com
- å¾®ä¿¡ï¼šyour_wechat_id

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®çš„å¯å‘ï¼š

- [nano-vLLM](https://github.com/tzular/mini-vllm) - ç®€æ´çš„æ•™å­¦å®ç°
- [mini-sglang](https://github.com/sgl-project/mini-sglang) - ç”Ÿäº§çº§å‚è€ƒå®ç°
- [vLLM](https://github.com/vllm-project/vllm) - å¼€åˆ›æ€§å·¥ä½œ
- [SGLang](https://github.com/sgl-project/sglang) - é«˜çº§ä¼˜åŒ–æŠ€æœ¯

---

<div align="center">

**å¼€å§‹ä½ çš„ LLM æ¨ç†ç³»ç»Ÿå­¦ä¹ ä¹‹æ—…ï¼** ğŸš€

Made with â¤ï¸ by AI Community

</div>
